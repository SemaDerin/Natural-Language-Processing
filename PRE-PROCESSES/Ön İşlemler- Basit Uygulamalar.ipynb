{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33fa05ef",
   "metadata": {},
   "source": [
    "# Basit NLP Uygulamaları\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65c477a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import textblob\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import TextBlob, Word\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"wordnet\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "nltk.download(\"averaged_perceptron_tagger\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e79a9b9",
   "metadata": {},
   "source": [
    "Yukarıdaki kod bloğu, nltk, textblob, ve pandas gibi Python kütüphanelerini içe aktararak, doğal dil işleme (NLP) ile ilgili işlemler yapmak için gereken araçları hazırlamaktadır.\n",
    "\n",
    "nltk kütüphanesi, doğal dil işleme için çok sayıda araç içerir. Bu kod bloğunda, corpus modülü içinden stopwords veri kümesi ve PorterStemmer stemmer sınıfı kullanılacaktır. Ayrıca, word_tokenize, pos_tag, ve ne_chunk fonksiyonları, metin analizi için sıklıkla kullanılan araçlardır.\n",
    "\n",
    "textblob kütüphanesi de doğal dil işleme ile ilgili çeşitli araçlar sunmaktadır. Bu kod bloğunda, TextBlob ve Word sınıfları kullanılacak. TextBlob sınıfı, metinler üzerinde farklı işlemler yapabilmek için kullanılan bir araçtır. Word sınıfı ise, bir kelime üzerinde farklı işlemler yapmak için kullanılır.\n",
    "\n",
    "pandas kütüphanesi ise, veri analizi ve işleme işleri için kullanılan bir kütüphanedir.\n",
    "\n",
    "Son olarak, nltk.download() fonksiyonu kullanılarak, bazı nltk veri kümeleri indirilir. Bu veri kümeleri, bazı NLP işlemlerinin gerçekleştirilebilmesi için gereklidir. Bu kod bloğunda, \"punkt\", \"wordnet\", \"stopwords\", ve \"averaged_perceptron_tagger\" adlı veri kümeleri indirilmektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a73e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "string= \"N-Gram uygulamasının nasıl çalıştığını görebilmek için buraya bir string metin ifadesi yazalım ve N-Gram nasıl kullanılıyor anlayalım.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e98fee44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N-Gram uygulamasının nasıl çalıştığını görebilmek için buraya bir string metin ifadesi yazalım ve N-Gram nasıl kullanılıyor anlayalım.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfff2c2",
   "metadata": {},
   "source": [
    "# N-GRAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1083c52f",
   "metadata": {},
   "source": [
    "N-Gram Nedir?\n",
    "\n",
    "N-gram, doğal dil işleme (NLP) alanında sıklıkla kullanılan bir yöntemdir. Metinlerin daha iyi anlaşılabilmesi için kullanılan bir tür dil modelidir.\n",
    "\n",
    "N-gram, bir metin içindeki ardışık N kelime kombinasyonlarını ifade eder. Örneğin, 2-gram (bigram) bir metin içindeki ardışık iki kelime kombinasyonlarını ifade eder. Benzer şekilde, 3-gram (trigram) bir metin içindeki ardışık üç kelime kombinasyonlarını ifade eder.\n",
    "\n",
    "N-gram modelleri, bir metnin anlamını çıkarmak, kelime sıklıklarını hesaplamak, kelime önerilerinde bulunmak, dil modelleri oluşturmak ve metin sınıflandırma işlemlerinde kullanmak gibi birçok farklı NLP görevinde kullanılabilir. Ayrıca, n-gram yöntemi dil öğrenme (language learning) ve karakter tanıma (character recognition) gibi alanlarda da kullanılır.\n",
    "\n",
    "Özellikle, büyük veri kümeleri üzerinde çalışırken, n-gram yöntemi önemli bir işlem yapar. N-gram yöntemi, büyük veri kümelerindeki anlamlı kelimelerin tespit edilmesinde, sözcüklerin sıklığına dayalı olarak etkili bir şekilde filtreleme yapmak için kullanılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdc2f4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['N-Gram']),\n",
       " WordList(['uygulamasının']),\n",
       " WordList(['nasıl']),\n",
       " WordList(['çalıştığını']),\n",
       " WordList(['görebilmek']),\n",
       " WordList(['için']),\n",
       " WordList(['buraya']),\n",
       " WordList(['bir']),\n",
       " WordList(['string']),\n",
       " WordList(['metin']),\n",
       " WordList(['ifadesi']),\n",
       " WordList(['yazalım']),\n",
       " WordList(['ve']),\n",
       " WordList(['N-Gram']),\n",
       " WordList(['nasıl']),\n",
       " WordList(['kullanılıyor']),\n",
       " WordList(['anlayalım'])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(string).ngrams(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43d6d6aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['N-Gram', 'uygulamasının']),\n",
       " WordList(['uygulamasının', 'nasıl']),\n",
       " WordList(['nasıl', 'çalıştığını']),\n",
       " WordList(['çalıştığını', 'görebilmek']),\n",
       " WordList(['görebilmek', 'için']),\n",
       " WordList(['için', 'buraya']),\n",
       " WordList(['buraya', 'bir']),\n",
       " WordList(['bir', 'string']),\n",
       " WordList(['string', 'metin']),\n",
       " WordList(['metin', 'ifadesi']),\n",
       " WordList(['ifadesi', 'yazalım']),\n",
       " WordList(['yazalım', 've']),\n",
       " WordList(['ve', 'N-Gram']),\n",
       " WordList(['N-Gram', 'nasıl']),\n",
       " WordList(['nasıl', 'kullanılıyor']),\n",
       " WordList(['kullanılıyor', 'anlayalım'])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(string).ngrams(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73a1ed2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['N-Gram', 'uygulamasının', 'nasıl']),\n",
       " WordList(['uygulamasının', 'nasıl', 'çalıştığını']),\n",
       " WordList(['nasıl', 'çalıştığını', 'görebilmek']),\n",
       " WordList(['çalıştığını', 'görebilmek', 'için']),\n",
       " WordList(['görebilmek', 'için', 'buraya']),\n",
       " WordList(['için', 'buraya', 'bir']),\n",
       " WordList(['buraya', 'bir', 'string']),\n",
       " WordList(['bir', 'string', 'metin']),\n",
       " WordList(['string', 'metin', 'ifadesi']),\n",
       " WordList(['metin', 'ifadesi', 'yazalım']),\n",
       " WordList(['ifadesi', 'yazalım', 've']),\n",
       " WordList(['yazalım', 've', 'N-Gram']),\n",
       " WordList(['ve', 'N-Gram', 'nasıl']),\n",
       " WordList(['N-Gram', 'nasıl', 'kullanılıyor']),\n",
       " WordList(['nasıl', 'kullanılıyor', 'anlayalım'])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(string).ngrams(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ebc2ec",
   "metadata": {},
   "source": [
    "# Part of Speech Tagging (POS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b8f825",
   "metadata": {},
   "source": [
    "Part Of Speech Tagging Nedir?\n",
    "\n",
    "Part-of-Speech (POS) tagging, bir metnin içindeki her kelimenin dilbilgisi özniteliklerinin (yani, ad, sıfat, fiil, zarf, edat, vb.) belirlenmesidir. POS tagging, doğal dil işleme (NLP) alanında sıklıkla kullanılan bir yöntemdir ve metinlerin otomatik olarak analiz edilmesinde ve anlamlandırılmasında önemli bir rol oynar.\n",
    "\n",
    "POS tagging, bir metindeki kelime özelliklerini belirleyerek, metnin anlamını daha doğru bir şekilde anlamak ve anlamsal açıdan benzer kelimeleri gruplamak için kullanılır. Örneğin, \"bank\" kelimesi birçok farklı anlama gelebilir - bir finans kurumu, bir nehir kenarı veya bir oturma yeri. Ancak, POS etiketleme yöntemi kullanılarak, cümledeki \"bank\" kelimesinin \"finans kurumu\" anlamında olduğu belirlenebilir.\n",
    "\n",
    "POS etiketleme, çeşitli NLP görevlerinde kullanılabilir, örneğin, kelime önerme, anlamsal analiz, cümle yapılandırma, kelime sıklığı hesaplama ve dil modelleri oluşturma gibi işlemlerde kullanılır. Ayrıca, makine öğrenmesi algoritmaları için önemli bir özellik öznitelikleri olarak da kullanılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4f3ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metin = \"\"\"\n",
    "Hamlet\n",
    "Romeo ve Juliet\n",
    "Kral Lear\n",
    "Othello\n",
    "Macbeth\n",
    "Jül Sezar\n",
    "Antonius ve Kleopatra\n",
    "Sıska Ayaklı Şövalye\n",
    "Fırtına\n",
    "Kış Masalı\n",
    "Kuru Gürültü\n",
    "Titus Andronicus\n",
    "İkinci Kral Henry\n",
    "Dört Mevsim\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2b0e55",
   "metadata": {},
   "source": [
    "Aşağıdaki kod bloğu, öncelikle \"metin\" adlı bir değişkene atanmış çok satırlı bir metni satır bazında ayırarak bir liste oluşturuyor. Daha sonra, \"pd.Series\" yöntemi kullanılarak bu liste, pandas kütüphanesinin \"Series\" sınıfı nesnesine dönüştürülüyor. Böylece, veri daha sonra pandas kütüphanesi tarafından kolayca işlenebilir hale geliyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f972222",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_metin = metin.split(\"\\n\")\n",
    "v_metin = pd.Series(v_metin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528a3af9",
   "metadata": {},
   "source": [
    "Aşağıdaki kod bloğu, \"v_metin\" isimli pandas Series nesnesinden, 1. indis değerinden (yani metnin ilk satırından) başlayarak son indis değerine kadar olan kısmını alarak bir alt dizi (slice) oluşturuyor. Böylece, ilk satır (yani metnin başlığı) dışındaki tüm satırları içeren bir liste oluşturuluyor. Bu liste daha sonra başka işlemlerde kullanılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88b8aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metin_vektoru = v_metin[1:len(v_metin)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d9f82f",
   "metadata": {},
   "source": [
    "Aşağıdaki  kod bloğu, bir pandas DataFrame oluşturur ve \"Hikayeler\" sütununda metinlerin küçük harfle yazılmasını, noktalama işaretlerinin ve sayıların kaldırılmasını sağlar. Bu sayede metinlerin işlenmesi ve analizi daha kolay hale gelir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "200cf8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\derin\\AppData\\Local\\Temp\\ipykernel_2168\\1189847113.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  mdf[\"Hikayeler\"] = mdf[\"Hikayeler\"].str.replace(\"[^\\w\\s]\",\"\")\n",
      "C:\\Users\\derin\\AppData\\Local\\Temp\\ipykernel_2168\\1189847113.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  mdf[\"Hikayeler\"] = mdf[\"Hikayeler\"].str.replace(\"\\d\",\"\")\n"
     ]
    }
   ],
   "source": [
    "mdf = pd.DataFrame(metin_vektoru, columns = [\"Hikayeler\"])\n",
    "mdf[\"Hikayeler\"] = mdf[\"Hikayeler\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "mdf[\"Hikayeler\"] = mdf[\"Hikayeler\"].str.replace(\"[^\\w\\s]\",\"\")\n",
    "mdf[\"Hikayeler\"] = mdf[\"Hikayeler\"].str.replace(\"\\d\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec8b8f8",
   "metadata": {},
   "source": [
    "Aşağıdaki od bloğu, NLTK kütüphanesi içerisinde yer alan İngilizce stop word listesini yükler ve sw değişkenine atar. Stop words, dilbilgisi kurallarına göre işlevsel olan ancak bir metindeki anlamı taşımayan kelimelerdir. Bu kelimelerin metin işleme aşamasında çıkarılması, veri analizi ve makine öğrenmesi modellerinde daha doğru sonuçlar elde etmek için yaygın bir yöntemdir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf197890",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words(\"english\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a957b",
   "metadata": {},
   "source": [
    "Aşağıdaki kod bloğu, metin verilerindeki İngilizce stop words (anlamı olmayan, yaygın kullanılan kelimeler) olarak adlandırılan kelimeleri çıkarır. Daha sonra, bu işlem yapılmış metin verilerini içeren bir DataFrame oluşturur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d80aa82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hikayeler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hamlet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>romeo juliet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kral lear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>othello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>macbeth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jül sezar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>antonius kleopatra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sıska ayaklı şövalye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fırtına</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kış masalı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kuru gürültü</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>titus andronicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ikinci kral henry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dört mevsim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Hikayeler\n",
       "1                 hamlet\n",
       "2           romeo juliet\n",
       "3              kral lear\n",
       "4                othello\n",
       "5                macbeth\n",
       "6              jül sezar\n",
       "7     antonius kleopatra\n",
       "8   sıska ayaklı şövalye\n",
       "9                fırtına\n",
       "10            kış masalı\n",
       "11          kuru gürültü\n",
       "12      titus andronicus\n",
       "13     ikinci kral henry\n",
       "14           dört mevsim"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf[\"Hikayeler\"] = mdf[\"Hikayeler\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n",
    "mdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17efddd2",
   "metadata": {},
   "source": [
    "Aşağıdaki kod, TextBlob kütüphanesi kullanılarak oluşturulan bir TextBlob nesnesi üzerinde tags özelliği kullanılarak, her kelimenin yanında bir etiket olarak gösterilen dilbilgisi etiketlerinden oluşan bir demet (tuple) listesi döndürür. Bu işlem, her kelimenin türünü (örneğin isim, sıfat, fiil, zarf vb.) belirlemek için bir dilbilgisi analizi işlemidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8554ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('romeo', 'NN'), ('juliet', 'NN')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(mdf[\"Hikayeler\"][2]).tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff0f8f3",
   "metadata": {},
   "source": [
    "Ağaşıdaki kod satırı, her satırın metnini TextBlob'a vererek metnin her kelimesini etiketlemek için kullanılır. Etiketler, her kelimenin türünü belirtir (örn. isim, sıfat, fiil vb.). Bu, metnin daha ayrıntılı bir analizini yapmak için kullanılabilir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57a31b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                                 [(hamlet, NN)]\n",
       "2                    [(romeo, NN), (juliet, NN)]\n",
       "3                       [(kral, JJ), (lear, NN)]\n",
       "4                                [(othello, NN)]\n",
       "5                               [(macbeth, NNS)]\n",
       "6                       [(jül, NN), (sezar, NN)]\n",
       "7              [(antonius, NN), (kleopatra, NN)]\n",
       "8     [(sıska, NN), (ayaklı, NN), (şövalye, NN)]\n",
       "9                                [(fırtına, NN)]\n",
       "10                     [(kış, NN), (masalı, NN)]\n",
       "11                   [(kuru, NN), (gürültü, NN)]\n",
       "12               [(titus, NN), (andronicus, NN)]\n",
       "13       [(ikinci, JJ), (kral, JJ), (henry, NN)]\n",
       "14                    [(dört, NN), (mevsim, NN)]\n",
       "Name: Hikayeler, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf[\"Hikayeler\"].apply(lambda x: TextBlob(x).tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b069d3a",
   "metadata": {},
   "source": [
    "# Chunking (Shallow Parsing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b3b25a",
   "metadata": {},
   "source": [
    "Chunking (Shallow Parsing) Nedir?\n",
    "\n",
    "Chunking, doğal dil işlemede kullanılan bir tekniktir ve cümlelerin gramer yapısına dayalı olarak belirli kelimelerin gruplandırılmasını içerir. Chunking, bir cümleyi parçalara ayırarak farklı kelime gruplarını tanımlamaya ve bu gruplara ait anahtar kelimeleri belirlemeye yarar. Bu sayede, bir cümle içindeki farklı öğelerin ne olduğu daha iyi anlaşılabilir. Shallow parsing olarak da adlandırılan Chunking, cümlelerin daha küçük parçalara ayrılmasına ve daha anlamlı bir yapıya sahip olmasına yardımcı olur.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f18f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"R and Python are useful data science tools for the new or old data scientists who eager to do efficent data science task\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ed6d245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R and Python are useful data science tools for the new or old data scientists who eager to do efficent data science task'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09fa364",
   "metadata": {},
   "source": [
    "Aşağıdaki kod bloğu, verilen cümledeki kelimelerin parçalarına ayrılmasını ve her kelime için etiketlenmiş parçaların listesini döndürür. Örneğin, \"I am happy\" cümlesi için çıktı aşağıdaki gibi olacaktır: Her kelimenin yanındaki etiket, o kelimenin dilbilgisel özelliğini belirtir. Yukarıdaki örnekte, \"I\" bir zamirdir (\"PRP\"), \"am\" bir fiil (\"VBP\") ve \"happy\" bir sıfat (\"JJ\") olarak etiketlenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3ca7d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('R', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Python', 'NNP'),\n",
       " ('are', 'VBP'),\n",
       " ('useful', 'JJ'),\n",
       " ('data', 'NNS'),\n",
       " ('science', 'NN'),\n",
       " ('tools', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('or', 'CC'),\n",
       " ('old', 'JJ'),\n",
       " ('data', 'NNS'),\n",
       " ('scientists', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('eager', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('do', 'VB'),\n",
       " ('efficent', 'JJ'),\n",
       " ('data', 'NNS'),\n",
       " ('science', 'NN'),\n",
       " ('task', 'NN')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = TextBlob(sentence).tags\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4a29de",
   "metadata": {},
   "source": [
    "Aşağıdaki kod bloğu, önceden belirlenmiş bir dilbilgisi kalıbına (regular expression) göre yapılan kelime gruplamasının (chunking) sonuçlarını görselleştirir. Yukarıdaki örnekte, \"NP\" adlı bir kalıp tanımlanmıştır, bu da \"determiner\", \"adjective\" ve \"noun\" ögelerinden oluşan bir özne grubu (noun phrase) olarak kabul edilen kelime öbeklerini yakalar. \"pos\" değişkeni, metnin her kelimesinin kelimelerinin cümle içindeki özelliklerini (part of speech) belirlemek için TextBlob kütüphanesi tarafından işlenir. Sonuçlar, \"rp.parse(pos)\" yöntemiyle elde edilir ve ardından \"draw()\" yöntemi kullanılarak görselleştirilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bfd224",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_exp = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "rp = nltk.RegexpParser(reg_exp)\n",
    "sonuclar = rp.parse(pos)\n",
    "sonuclar.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2e96df",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea54bd",
   "metadata": {},
   "source": [
    "Named Entity Recognition Nedir?\n",
    "\n",
    "Named Entity Recognition (NER), doğal dil işlemede kullanılan bir tekniktir. Amacı, verilen bir metin içindeki isimler, özel isimler, tarihler, yer adları gibi belirli türden kelimeleri tanımlamak ve bu kelimelerin anlamsal olarak birbirleriyle olan ilişkilerini tespit etmektir. Bu teknik sayesinde, metinlerde geçen önemli kelimelerin tanımlanması, sınıflandırılması ve anlamsal olarak bağlantı kurulması mümkün hale gelir. NER, genellikle bilgi çıkarma, metin sınıflandırma ve özetleme gibi doğal dil işleme uygulamalarında kullanılır.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5faa9ed",
   "metadata": {},
   "source": [
    "Aşağıdaki kod bloğu, nltk kütüphanesindeki maxent_ne_chunker ve words modüllerinin indirilmesini sağlar. Bu modüller, isim öğelerinin tanınması için kullanılan ne_chunk() fonksiyonu tarafından kullanılır. maxent_ne_chunker modeli, maksimum entropi yöntemi kullanarak kelime özniteliklerini kullanarak öğelerin isim öğeleri olup olmadığını belirler. words modülü, dilin kelime dağarcığını içerir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5c49e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"maxent_ne_chunker\", quiet=True)\n",
    "nltk.download(\"words\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62330fbd",
   "metadata": {},
   "source": [
    "Aşağıdaki kod bloğu, \"cumle\" değişkeninde tanımlanan metindeki kelimelerin parçalanmasını (tokenization), kelimelerin parçalanmasından sonra oluşan parçaların hangi dilbilgisi kategorisine (part of speech) ait olduğunu belirlemek için etiketleme (POS tagging) gerçekleştirir. Daha sonra, \"ne_chunk\" fonksiyonu ile bu etiketli parçaların isim öbekleri, tarihler, yerler vb. gibi öğeleri tanımak için adlandırılmış varlık tanıma (Named Entity Recognition) gerçekleştirir. Sonuç, her kelimenin etiketi ve her tanımlanmış varlığın türü ile birlikte bir ağaç yapısı olarak gösterilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dbb490",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = \"Hadley is creative people who work for R Studio AND he attented conference at Newyork last year\"\n",
    "print(ne_chunk(pos_tag(word_tokenize(sentence2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a38d440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
